{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "230553a7-6e45-4c66-8ea5-43380ef5e69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "import dlt\n",
    "import duckdb\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97d4741c-8b57-405d-8103-c779f17b5c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2024-02-17 16:32:31--  https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2022-01.parquet\n",
      "Resolving d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)... 18.161.108.141, 18.161.108.77, 18.161.108.231, ...\n",
      "Connecting to d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)|18.161.108.141|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1254291 (1.2M) [binary/octet-stream]\n",
      "Saving to: ‘output.parquet’\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  4%  381K 3s\n",
      "    50K .......... .......... .......... .......... ..........  8%  509K 3s\n",
      "   100K .......... .......... .......... .......... .......... 12% 1.24M 2s\n",
      "   150K .......... .......... .......... .......... .......... 16% 1.27M 2s\n",
      "   200K .......... .......... .......... .......... .......... 20% 1.24M 1s\n",
      "   250K .......... .......... .......... .......... .......... 24% 1.84M 1s\n",
      "   300K .......... .......... .......... .......... .......... 28% 1.89M 1s\n",
      "   350K .......... .......... .......... .......... .......... 32% 1.76M 1s\n",
      "   400K .......... .......... .......... .......... .......... 36% 2.61M 1s\n",
      "   450K .......... .......... .......... .......... .......... 40% 3.64M 1s\n",
      "   500K .......... .......... .......... .......... .......... 44% 3.54M 1s\n",
      "   550K .......... .......... .......... .......... .......... 48% 3.86M 1s\n",
      "   600K .......... .......... .......... .......... .......... 53% 3.64M 0s\n",
      "   650K .......... .......... .......... .......... .......... 57% 4.09M 0s\n",
      "   700K .......... .......... .......... .......... .......... 61% 4.85M 0s\n",
      "   750K .......... .......... .......... .......... .......... 65% 3.77M 0s\n",
      "   800K .......... .......... .......... .......... .......... 69% 5.13M 0s\n",
      "   850K .......... .......... .......... .......... .......... 73% 5.69M 0s\n",
      "   900K .......... .......... .......... .......... .......... 77% 5.84M 0s\n",
      "   950K .......... .......... .......... .......... .......... 81% 6.36M 0s\n",
      "  1000K .......... .......... .......... .......... .......... 85% 5.17M 0s\n",
      "  1050K .......... .......... .......... .......... .......... 89% 7.36M 0s\n",
      "  1100K .......... .......... .......... .......... .......... 93% 7.44M 0s\n",
      "  1150K .......... .......... .......... .......... .......... 97% 7.57M 0s\n",
      "  1200K .......... .......... ....                            100% 9.62M=0.6s\n",
      "\n",
      "2024-02-17 16:32:32 (2.00 MB/s) - ‘output.parquet’ saved [1254291/1254291]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2022-01.parquet\"\n",
    "file_name = \"output.parquet\"\n",
    "os.system(f\"wget {url} -O {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "319a66ac-52f2-49e7-ad3b-c1fc4fda202f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pa.parquet.read_pandas(file_name, columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59e0f653-171b-40d0-bce3-d5c089b243dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_file = pq.ParquetFile(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0e8ec16-9b5a-44c4-9bdb-2ad9f4dec5ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyarrow.Table\n",
       "VendorID: int64\n",
       "lpep_pickup_datetime: timestamp[us]\n",
       "lpep_dropoff_datetime: timestamp[us]\n",
       "store_and_fwd_flag: string\n",
       "RatecodeID: double\n",
       "PULocationID: int64\n",
       "DOLocationID: int64\n",
       "passenger_count: double\n",
       "trip_distance: double\n",
       "fare_amount: double\n",
       "extra: double\n",
       "mta_tax: double\n",
       "tip_amount: double\n",
       "tolls_amount: double\n",
       "ehail_fee: null\n",
       "improvement_surcharge: double\n",
       "total_amount: double\n",
       "payment_type: double\n",
       "trip_type: double\n",
       "congestion_surcharge: double\n",
       "----\n",
       "VendorID: [[2,1,1,2,2,...,2,2,2,2,2]]\n",
       "lpep_pickup_datetime: [[2022-01-01 00:14:21.000000,2022-01-01 00:20:55.000000,2022-01-01 00:57:02.000000,2022-01-01 00:07:42.000000,2022-01-01 00:07:50.000000,...,2022-01-31 23:25:00.000000,2022-01-31 23:52:00.000000,2022-01-31 23:17:00.000000,2022-01-31 23:45:00.000000,2022-01-31 23:52:00.000000]]\n",
       "lpep_dropoff_datetime: [[2022-01-01 00:15:33.000000,2022-01-01 00:29:38.000000,2022-01-01 01:13:14.000000,2022-01-01 00:15:57.000000,2022-01-01 00:28:52.000000,...,2022-01-31 23:33:00.000000,2022-02-01 00:10:00.000000,2022-01-31 23:36:00.000000,2022-01-31 23:55:00.000000,2022-02-01 00:26:00.000000]]\n",
       "store_and_fwd_flag: [[\"N\",\"N\",\"N\",\"N\",\"N\",...,null,null,null,null,null]]\n",
       "RatecodeID: [[1,1,1,1,1,...,null,null,null,null,null]]\n",
       "PULocationID: [[42,116,41,181,33,...,40,36,75,116,225]]\n",
       "DOLocationID: [[42,41,140,181,170,...,65,61,167,166,179]]\n",
       "passenger_count: [[1,1,1,1,1,...,null,null,null,null,null]]\n",
       "trip_distance: [[0.44,2.1,3.7,1.69,6.26,...,1.4,2.97,3.7,1.88,9.6]]\n",
       "fare_amount: [[3.5,9.5,14.5,8,22,...,8.38,14.92,16.26,9.48,32.18]]\n",
       "..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parquet_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "229eeb64-b6cc-4c32-a8fa-b5fc49687817",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = dlt.pipeline(pipeline_name=\"taxi_data\",\n",
    "\t\t\t\t\t\tdestination='duckdb', \n",
    "\t\t\t\t\t\tdataset_name='taxi_rides')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7aa0af5f-8c43-437b-ab2f-e16a5b0c4a57",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m info \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mrun(\u001b[43mdata\u001b[49m, \n\u001b[1;32m      2\u001b[0m                     table_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musers\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      3\u001b[0m                     write_disposition\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "info = pipeline.run(data, \n",
    "                    table_name=\"users\", \n",
    "                    write_disposition=\"replace\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e36fd150-37da-4017-b901-3e721f01b770",
   "metadata": {},
   "source": [
    "pip install dlt[parquet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14123c5e-f78d-4134-9e26-fcda342c49f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "PipelineStepFailed",
     "evalue": "Pipeline execution failed at stage extract with exception:\n\n<class 'dlt.extract.exceptions.ResourceNameMissing'>\nResource name is missing. If you create a resource directly from data ie. from a list you must pass the name explicitly in `name` argument.\n        Please note that for resources created from functions or generators, the name is the function name by default.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceNameMissing\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/pipeline/pipeline.py:378\u001b[0m, in \u001b[0;36mPipeline.extract\u001b[0;34m(self, data, table_name, parent_table_name, write_disposition, columns, primary_key, schema, max_parallel_items, workers, schema_contract)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_destination_capabilities():\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;66;03m# extract all sources\u001b[39;00m\n\u001b[0;32m--> 378\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m source \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdata_to_sources\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparent_table_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwrite_disposition\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprimary_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema_contract\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m source\u001b[38;5;241m.\u001b[39mexhausted:\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/extract/extract.py:113\u001b[0m, in \u001b[0;36mdata_to_sources\u001b[0;34m(data, pipeline, schema, table_name, parent_table_name, write_disposition, columns, primary_key, schema_contract)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 113\u001b[0m         \u001b[43mappend_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/extract/extract.py:104\u001b[0m, in \u001b[0;36mdata_to_sources.<locals>.append_data\u001b[0;34m(data_item)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;66;03m# iterator/iterable/generator\u001b[39;00m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;66;03m# create resource first without table template\u001b[39;00m\n\u001b[1;32m    103\u001b[0m     resources\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 104\u001b[0m         \u001b[43mDltResource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_item\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtable_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipeline_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/extract/resource.py:129\u001b[0m, in \u001b[0;36mDltResource.from_data\u001b[0;34m(cls, data, name, section, hints, selected, data_from, incremental)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m name:\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResourceNameMissing()\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# wrap additional types\u001b[39;00m\n",
      "\u001b[0;31mResourceNameMissing\u001b[0m: Resource name is missing. If you create a resource directly from data ie. from a list you must pass the name explicitly in `name` argument.\n        Please note that for resources created from functions or generators, the name is the function name by default.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mPipelineStepFailed\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m info \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader_file_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparquet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/pipeline/pipeline.py:193\u001b[0m, in \u001b[0;36mwith_runtime_trace.<locals>.decorator.<locals>._wrap\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trace:\n\u001b[1;32m    191\u001b[0m         trace_step \u001b[38;5;241m=\u001b[39m start_trace_step(trace, cast(TPipelineStep, f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m), \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 193\u001b[0m     step_info \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m step_info\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/pipeline/pipeline.py:238\u001b[0m, in \u001b[0;36mwith_config_section.<locals>.decorator.<locals>._wrap\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrap\u001b[39m(\u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# add section context to the container to be used by all configuration without explicit sections resolution\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inject_section(\n\u001b[1;32m    236\u001b[0m         ConfigSectionContext(pipeline_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipeline_name, sections\u001b[38;5;241m=\u001b[39msections)\n\u001b[1;32m    237\u001b[0m     ):\n\u001b[0;32m--> 238\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/pipeline/pipeline.py:619\u001b[0m, in \u001b[0;36mPipeline.run\u001b[0;34m(self, data, destination, staging, dataset_name, credentials, table_name, write_disposition, columns, primary_key, schema, loader_file_format, schema_contract)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;66;03m# extract from the source\u001b[39;00m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 619\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtable_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtable_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwrite_disposition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrite_disposition\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprimary_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprimary_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema_contract\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema_contract\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize(loader_file_format\u001b[38;5;241m=\u001b[39mloader_file_format)\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload(destination, dataset_name, credentials\u001b[38;5;241m=\u001b[39mcredentials)\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/pipeline/pipeline.py:193\u001b[0m, in \u001b[0;36mwith_runtime_trace.<locals>.decorator.<locals>._wrap\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trace:\n\u001b[1;32m    191\u001b[0m         trace_step \u001b[38;5;241m=\u001b[39m start_trace_step(trace, cast(TPipelineStep, f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m), \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 193\u001b[0m     step_info \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m step_info\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/pipeline/pipeline.py:164\u001b[0m, in \u001b[0;36mwith_schemas_sync.<locals>._wrap\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_schema_storage\u001b[38;5;241m.\u001b[39mlive_schemas:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# refresh live schemas in storage or import schema path\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_schema_storage\u001b[38;5;241m.\u001b[39mcommit_live_schema(name)\n\u001b[0;32m--> 164\u001b[0m rv \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;66;03m# save modified live schemas\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_schema_storage\u001b[38;5;241m.\u001b[39mlive_schemas:\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/pipeline/pipeline.py:151\u001b[0m, in \u001b[0;36mwith_state_sync.<locals>.decorator.<locals>._wrap\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmanaged_state(extract_state\u001b[38;5;241m=\u001b[39mshould_extract_state) \u001b[38;5;28;01mas\u001b[39;00m state:\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;66;03m# add the state to container as a context\u001b[39;00m\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container\u001b[38;5;241m.\u001b[39minjectable_context(StateInjectableContext(state\u001b[38;5;241m=\u001b[39mstate)):\n\u001b[0;32m--> 151\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/pipeline/pipeline.py:238\u001b[0m, in \u001b[0;36mwith_config_section.<locals>.decorator.<locals>._wrap\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrap\u001b[39m(\u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# add section context to the container to be used by all configuration without explicit sections resolution\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inject_section(\n\u001b[1;32m    236\u001b[0m         ConfigSectionContext(pipeline_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipeline_name, sections\u001b[38;5;241m=\u001b[39msections)\n\u001b[1;32m    237\u001b[0m     ):\n\u001b[0;32m--> 238\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/pipeline/pipeline.py:403\u001b[0m, in \u001b[0;36mPipeline.extract\u001b[0;34m(self, data, table_name, parent_table_name, write_disposition, columns, primary_key, schema, max_parallel_items, workers, schema_contract)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    402\u001b[0m     step_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_step_info(extract_step)\n\u001b[0;32m--> 403\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PipelineStepFailed(\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextract\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    406\u001b[0m         extract_step\u001b[38;5;241m.\u001b[39mcurrent_load_id,\n\u001b[1;32m    407\u001b[0m         exc,\n\u001b[1;32m    408\u001b[0m         step_info,\n\u001b[1;32m    409\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mPipelineStepFailed\u001b[0m: Pipeline execution failed at stage extract with exception:\n\n<class 'dlt.extract.exceptions.ResourceNameMissing'>\nResource name is missing. If you create a resource directly from data ie. from a list you must pass the name explicitly in `name` argument.\n        Please note that for resources created from functions or generators, the name is the function name by default."
     ]
    }
   ],
   "source": [
    "info = pipeline.run(url, loader_file_format=\"parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b7fe552b-94d6-4017-a075-138568974cf0",
   "metadata": {},
   "outputs": [
    {
     "ename": "PipelineStepFailed",
     "evalue": "Pipeline execution failed at stage sync with exception:\n\n<class 'dlt.common.configuration.exceptions.ConfigFieldMissingException'>\nFollowing fields are missing: ['bucket_url'] in configuration with spec FilesystemDestinationClientConfiguration\n\tfor field \"bucket_url\" config providers and keys were tried in following order:\n\t\tIn Environment Variables key PIPELINE__DESTINATION__FILESYSTEM__BUCKET_URL was not found.\n\t\tIn Environment Variables key PIPELINE__DESTINATION__BUCKET_URL was not found.\n\t\tIn Environment Variables key PIPELINE__BUCKET_URL was not found.\n\t\tIn secrets.toml key pipeline.destination.filesystem.bucket_url was not found.\n\t\tIn secrets.toml key pipeline.destination.bucket_url was not found.\n\t\tIn secrets.toml key pipeline.bucket_url was not found.\n\t\tIn Environment Variables key DESTINATION__FILESYSTEM__BUCKET_URL was not found.\n\t\tIn Environment Variables key DESTINATION__BUCKET_URL was not found.\n\t\tIn Environment Variables key BUCKET_URL was not found.\n\t\tIn secrets.toml key destination.filesystem.bucket_url was not found.\n\t\tIn secrets.toml key destination.bucket_url was not found.\n\t\tIn secrets.toml key bucket_url was not found.\nWARNING: dlt looks for .dlt folder in your current working directory and your cwd (/workspaces/RKZoomCamp2024) is different from directory of your pipeline script (/home/codespace/.local/lib/python3.10/site-packages).\nIf you keep your secret files in the same folder as your pipeline script but run your script from some other folder, secrets/configs will not be found\nPlease refer to https://dlthub.com/docs/general-usage/credentials for more information\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConfigFieldMissingException\u001b[0m               Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/pipeline/pipeline.py:659\u001b[0m, in \u001b[0;36mPipeline.sync_destination\u001b[0;34m(self, destination, staging, dataset_name)\u001b[0m\n\u001b[1;32m    658\u001b[0m restored_schemas: Sequence[Schema] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 659\u001b[0m remote_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_restore_state_from_destination\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    661\u001b[0m \u001b[38;5;66;03m# if remote state is newer or same\u001b[39;00m\n\u001b[1;32m    662\u001b[0m \u001b[38;5;66;03m# print(f'REMOTE STATE: {(remote_state or {}).get(\"_state_version\")} >= {state[\"_state_version\"]}')\u001b[39;00m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;66;03m# TODO: check if remote_state[\"_state_version\"] is not in 10 recent version. then we know remote is newer.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/pipeline/pipeline.py:1371\u001b[0m, in \u001b[0;36mPipeline._restore_state_from_destination\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1370\u001b[0m     schema \u001b[38;5;241m=\u001b[39m Schema(schema_name)\n\u001b[0;32m-> 1371\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_destination_clients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mas\u001b[39;00m job_client:\n\u001b[1;32m   1372\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(job_client, WithStateSync):\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/pipeline/pipeline.py:1110\u001b[0m, in \u001b[0;36mPipeline._get_destination_clients\u001b[0;34m(self, schema, initial_config, initial_staging_config)\u001b[0m\n\u001b[1;32m   1109\u001b[0m     \u001b[38;5;66;03m# create the client - that will also resolve the config\u001b[39;00m\n\u001b[0;32m-> 1110\u001b[0m     staging_client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstaging\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_staging_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m initial_config:\n\u001b[1;32m   1112\u001b[0m     \u001b[38;5;66;03m# config is not provided then get it with injected credentials\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/common/destination/reference.py:562\u001b[0m, in \u001b[0;36mDestination.client\u001b[0;34m(self, schema, initial_config)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a configured instance of the destination's job client\"\"\"\u001b[39;00m\n\u001b[0;32m--> 562\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient_class(schema, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfiguration\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_config\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/common/destination/reference.py:475\u001b[0m, in \u001b[0;36mDestination.configuration\u001b[0;34m(self, initial_config)\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get a fully resolved destination config from the initial config\"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[43mresolve_configuration\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m    \u001b[49m\u001b[43msections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mknown_sections\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDESTINATION\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdestination_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Already populated values will supersede resolved env config\u001b[39;49;00m\n\u001b[1;32m    479\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexplicit_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m config\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/common/configuration/resolve.py:65\u001b[0m, in \u001b[0;36mresolve_configuration\u001b[0;34m(config, sections, explicit_value, accept_partial)\u001b[0m\n\u001b[1;32m     63\u001b[0m         log_traces(\u001b[38;5;28;01mNone\u001b[39;00m, config\u001b[38;5;241m.\u001b[39m__section__, \u001b[38;5;28mtype\u001b[39m(config), explicit_value, \u001b[38;5;28;01mNone\u001b[39;00m, traces)\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_resolve_configuration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msections\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexplicit_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_partial\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/common/configuration/resolve.py:154\u001b[0m, in \u001b[0;36m_resolve_configuration\u001b[0;34m(config, explicit_sections, embedded_sections, explicit_value, accept_partial)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m config\u001b[38;5;241m.\u001b[39mis_resolved():\n\u001b[0;32m--> 154\u001b[0m     \u001b[43m_resolve_config_fields\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexplicit_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexplicit_sections\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedded_sections\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_partial\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;66;03m# full configuration was resolved\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/common/configuration/resolve.py:274\u001b[0m, in \u001b[0;36m_resolve_config_fields\u001b[0;34m(config, explicit_values, explicit_sections, embedded_sections, accept_partial)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m unresolved_fields:\n\u001b[0;32m--> 274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ConfigFieldMissingException(\u001b[38;5;28mtype\u001b[39m(config)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, unresolved_fields)\n",
      "\u001b[0;31mConfigFieldMissingException\u001b[0m: Following fields are missing: ['bucket_url'] in configuration with spec FilesystemDestinationClientConfiguration\n\tfor field \"bucket_url\" config providers and keys were tried in following order:\n\t\tIn Environment Variables key PIPELINE__DESTINATION__FILESYSTEM__BUCKET_URL was not found.\n\t\tIn Environment Variables key PIPELINE__DESTINATION__BUCKET_URL was not found.\n\t\tIn Environment Variables key PIPELINE__BUCKET_URL was not found.\n\t\tIn secrets.toml key pipeline.destination.filesystem.bucket_url was not found.\n\t\tIn secrets.toml key pipeline.destination.bucket_url was not found.\n\t\tIn secrets.toml key pipeline.bucket_url was not found.\n\t\tIn Environment Variables key DESTINATION__FILESYSTEM__BUCKET_URL was not found.\n\t\tIn Environment Variables key DESTINATION__BUCKET_URL was not found.\n\t\tIn Environment Variables key BUCKET_URL was not found.\n\t\tIn secrets.toml key destination.filesystem.bucket_url was not found.\n\t\tIn secrets.toml key destination.bucket_url was not found.\n\t\tIn secrets.toml key bucket_url was not found.\nWARNING: dlt looks for .dlt folder in your current working directory and your cwd (/workspaces/RKZoomCamp2024) is different from directory of your pipeline script (/home/codespace/.local/lib/python3.10/site-packages).\nIf you keep your secret files in the same folder as your pipeline script but run your script from some other folder, secrets/configs will not be found\nPlease refer to https://dlthub.com/docs/general-usage/credentials for more information\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mPipelineStepFailed\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 20\u001b[0m\n\u001b[1;32m     10\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m dlt\u001b[38;5;241m.\u001b[39mpipeline(\n\u001b[1;32m     11\u001b[0m     pipeline_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpipeline\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m#destination='dlt.destinations.filesystem'\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     dataset_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmydata\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#load_info = pipeline.run(data)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#load_info = pipeline.run(data, table_name=\"zone_lookup\")\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m load_info \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzone_lookup\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(load_info)\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/pipeline/pipeline.py:193\u001b[0m, in \u001b[0;36mwith_runtime_trace.<locals>.decorator.<locals>._wrap\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trace:\n\u001b[1;32m    191\u001b[0m         trace_step \u001b[38;5;241m=\u001b[39m start_trace_step(trace, cast(TPipelineStep, f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m), \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 193\u001b[0m     step_info \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m step_info\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/pipeline/pipeline.py:238\u001b[0m, in \u001b[0;36mwith_config_section.<locals>.decorator.<locals>._wrap\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrap\u001b[39m(\u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# add section context to the container to be used by all configuration without explicit sections resolution\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inject_section(\n\u001b[1;32m    236\u001b[0m         ConfigSectionContext(pipeline_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipeline_name, sections\u001b[38;5;241m=\u001b[39msections)\n\u001b[1;32m    237\u001b[0m     ):\n\u001b[0;32m--> 238\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/pipeline/pipeline.py:600\u001b[0m, in \u001b[0;36mPipeline.run\u001b[0;34m(self, data, destination, staging, dataset_name, credentials, table_name, write_disposition, columns, primary_key, schema, loader_file_format, schema_contract)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;66;03m# sync state with destination\u001b[39;00m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mrestore_from_destination\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfull_refresh\n\u001b[1;32m    597\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state_restored\n\u001b[1;32m    598\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdestination \u001b[38;5;129;01mor\u001b[39;00m destination)\n\u001b[1;32m    599\u001b[0m ):\n\u001b[0;32m--> 600\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_destination\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdestination\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstaging\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    601\u001b[0m     \u001b[38;5;66;03m# sync only once\u001b[39;00m\n\u001b[1;32m    602\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state_restored \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/pipeline/pipeline.py:164\u001b[0m, in \u001b[0;36mwith_schemas_sync.<locals>._wrap\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_schema_storage\u001b[38;5;241m.\u001b[39mlive_schemas:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# refresh live schemas in storage or import schema path\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_schema_storage\u001b[38;5;241m.\u001b[39mcommit_live_schema(name)\n\u001b[0;32m--> 164\u001b[0m rv \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;66;03m# save modified live schemas\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_schema_storage\u001b[38;5;241m.\u001b[39mlive_schemas:\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/dlt/pipeline/pipeline.py:730\u001b[0m, in \u001b[0;36mPipeline.sync_destination\u001b[0;34m(self, destination, staging, dataset_name)\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_state(state)\n\u001b[1;32m    729\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[0;32m--> 730\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PipelineStepFailed(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msync\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m, ex, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mex\u001b[39;00m\n",
      "\u001b[0;31mPipelineStepFailed\u001b[0m: Pipeline execution failed at stage sync with exception:\n\n<class 'dlt.common.configuration.exceptions.ConfigFieldMissingException'>\nFollowing fields are missing: ['bucket_url'] in configuration with spec FilesystemDestinationClientConfiguration\n\tfor field \"bucket_url\" config providers and keys were tried in following order:\n\t\tIn Environment Variables key PIPELINE__DESTINATION__FILESYSTEM__BUCKET_URL was not found.\n\t\tIn Environment Variables key PIPELINE__DESTINATION__BUCKET_URL was not found.\n\t\tIn Environment Variables key PIPELINE__BUCKET_URL was not found.\n\t\tIn secrets.toml key pipeline.destination.filesystem.bucket_url was not found.\n\t\tIn secrets.toml key pipeline.destination.bucket_url was not found.\n\t\tIn secrets.toml key pipeline.bucket_url was not found.\n\t\tIn Environment Variables key DESTINATION__FILESYSTEM__BUCKET_URL was not found.\n\t\tIn Environment Variables key DESTINATION__BUCKET_URL was not found.\n\t\tIn Environment Variables key BUCKET_URL was not found.\n\t\tIn secrets.toml key destination.filesystem.bucket_url was not found.\n\t\tIn secrets.toml key destination.bucket_url was not found.\n\t\tIn secrets.toml key bucket_url was not found.\nWARNING: dlt looks for .dlt folder in your current working directory and your cwd (/workspaces/RKZoomCamp2024) is different from directory of your pipeline script (/home/codespace/.local/lib/python3.10/site-packages).\nIf you keep your secret files in the same folder as your pipeline script but run your script from some other folder, secrets/configs will not be found\nPlease refer to https://dlthub.com/docs/general-usage/credentials for more information\n"
     ]
    }
   ],
   "source": [
    "import dlt\n",
    "import pandas as pd\n",
    "\n",
    "owid_disasters_csv = (\n",
    "    \"https://s3.amazonaws.com/nyc-tlc/misc/taxi+_zone_lookup.csv\"\n",
    ")\n",
    "df = pd.read_csv(owid_disasters_csv)\n",
    "data = df.to_dict(orient=\"records\")\n",
    "\n",
    "pipeline = dlt.pipeline(\n",
    "    pipeline_name='pipeline',\n",
    "    #destination='dlt.destinations.filesystem'\n",
    "    destination='bigquery',\n",
    "    staging='filesystem', # add this to activate the staging location\n",
    "    dataset_name='mydata'\n",
    ")\n",
    "\n",
    "#load_info = pipeline.run(data)\n",
    "#load_info = pipeline.run(data, table_name=\"zone_lookup\")\n",
    "load_info = pipeline.run(data, table_name=\"zone_lookup\")\n",
    "\n",
    "print(load_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eec58b58-dfb4-4122-abec-24e14fcbd64a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1b6fc0-6783-455c-a2ea-52ff42269a04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1bc6451e-12b1-4c3c-b9cf-0955b7044d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = duckdb.connect(f\"{pipeline.pipeline_name}.duckdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3859bfa2-aeb6-4882-84f4-a07681cf7c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.sql(f\"SET search_path = '{pipeline.dataset_name}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "efeaa246-8576-41f0-b65c-01f2027688c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌──────────┬─────────┬─────────────────────┬──────────────────────┬────────────────────────────────────────┬───────────┐\n",
       "│ database │ schema  │        name         │     column_names     │              column_types              │ temporary │\n",
       "│ varchar  │ varchar │       varchar       │      varchar[]       │               varchar[]                │  boolean  │\n",
       "├──────────┼─────────┼─────────────────────┼──────────────────────┼────────────────────────────────────────┼───────────┤\n",
       "│ pipeline │ mydata  │ _dlt_loads          │ [load_id, schema_n…  │ [VARCHAR, VARCHAR, BIGINT, TIMESTAMP…  │ false     │\n",
       "│ pipeline │ mydata  │ _dlt_pipeline_state │ [version, engine_v…  │ [BIGINT, BIGINT, VARCHAR, VARCHAR, T…  │ false     │\n",
       "│ pipeline │ mydata  │ _dlt_version        │ [version, engine_v…  │ [BIGINT, BIGINT, TIMESTAMP WITH TIME…  │ false     │\n",
       "│ pipeline │ mydata  │ zone_lookup         │ [location_id, boro…  │ [BIGINT, VARCHAR, VARCHAR, VARCHAR, …  │ false     │\n",
       "└──────────┴─────────┴─────────────────────┴──────────────────────┴────────────────────────────────────────┴───────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(conn.sql(\"DESCRIBE\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "51f6f903-11e5-45dd-bab3-5af603831581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_id</th>\n",
       "      <th>borough</th>\n",
       "      <th>zone</th>\n",
       "      <th>service_zone</th>\n",
       "      <th>_dlt_load_id</th>\n",
       "      <th>_dlt_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>EWR</td>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>EWR</td>\n",
       "      <td>1708195132.3040164</td>\n",
       "      <td>2fl3giQ/bQWXXg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Queens</td>\n",
       "      <td>Jamaica Bay</td>\n",
       "      <td>Boro Zone</td>\n",
       "      <td>1708195132.3040164</td>\n",
       "      <td>5yn65bCL+3HUoQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>Allerton/Pelham Gardens</td>\n",
       "      <td>Boro Zone</td>\n",
       "      <td>1708195132.3040164</td>\n",
       "      <td>hFXu8PoyWgz9FA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Alphabet City</td>\n",
       "      <td>Yellow Zone</td>\n",
       "      <td>1708195132.3040164</td>\n",
       "      <td>dRUGHtcs/Yb2uQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>Arden Heights</td>\n",
       "      <td>Boro Zone</td>\n",
       "      <td>1708195132.3040164</td>\n",
       "      <td>IohlN9Qh82hZ4w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>261</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>World Trade Center</td>\n",
       "      <td>Yellow Zone</td>\n",
       "      <td>1708195132.3040164</td>\n",
       "      <td>PyyGcG0hZHHkwg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>262</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Yorkville East</td>\n",
       "      <td>Yellow Zone</td>\n",
       "      <td>1708195132.3040164</td>\n",
       "      <td>0dqCCTG2ouSAbA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>263</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Yorkville West</td>\n",
       "      <td>Yellow Zone</td>\n",
       "      <td>1708195132.3040164</td>\n",
       "      <td>WNtzLun9PNJvtw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>264</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NV</td>\n",
       "      <td>None</td>\n",
       "      <td>1708195132.3040164</td>\n",
       "      <td>BIyoDfUPFHV+iQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>265</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1708195132.3040164</td>\n",
       "      <td>ndFjx2cpx8zZOg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>265 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     location_id        borough                     zone service_zone  \\\n",
       "0              1            EWR           Newark Airport          EWR   \n",
       "1              2         Queens              Jamaica Bay    Boro Zone   \n",
       "2              3          Bronx  Allerton/Pelham Gardens    Boro Zone   \n",
       "3              4      Manhattan            Alphabet City  Yellow Zone   \n",
       "4              5  Staten Island            Arden Heights    Boro Zone   \n",
       "..           ...            ...                      ...          ...   \n",
       "260          261      Manhattan       World Trade Center  Yellow Zone   \n",
       "261          262      Manhattan           Yorkville East  Yellow Zone   \n",
       "262          263      Manhattan           Yorkville West  Yellow Zone   \n",
       "263          264        Unknown                       NV         None   \n",
       "264          265        Unknown                     None         None   \n",
       "\n",
       "           _dlt_load_id         _dlt_id  \n",
       "0    1708195132.3040164  2fl3giQ/bQWXXg  \n",
       "1    1708195132.3040164  5yn65bCL+3HUoQ  \n",
       "2    1708195132.3040164  hFXu8PoyWgz9FA  \n",
       "3    1708195132.3040164  dRUGHtcs/Yb2uQ  \n",
       "4    1708195132.3040164  IohlN9Qh82hZ4w  \n",
       "..                  ...             ...  \n",
       "260  1708195132.3040164  PyyGcG0hZHHkwg  \n",
       "261  1708195132.3040164  0dqCCTG2ouSAbA  \n",
       "262  1708195132.3040164  WNtzLun9PNJvtw  \n",
       "263  1708195132.3040164  BIyoDfUPFHV+iQ  \n",
       "264  1708195132.3040164  ndFjx2cpx8zZOg  \n",
       "\n",
       "[265 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stats_table = conn.sql(\"SELECT * FROM zone_lookup\").df()\n",
    "display(stats_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca4eb08-c988-4eb0-9594-ad982fd656d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
